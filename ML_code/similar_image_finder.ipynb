{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "zTMuKqrhOgkj",
        "outputId": "9fba8736-46a0-4ecd-999b-ba18142d6bcb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \"\"\"\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    126\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kp0WKKVpYGUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JmSInTMcYGKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbmWtWenYGCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Extracting image paths\n",
        "file_path = os.listdir('dataset')\n",
        "print(len(file_path))\n",
        "\n",
        "train_files, test_files = train_test_split(file_path, test_size = 0.15)\n",
        "\n",
        "print(\"Number of Training Images:\",len(train_files))\n",
        "print(\"Number of Test Images: \",len(test_files))\n",
        "train_files = pd.DataFrame(train_files,columns=['filepath'])\n",
        "test_files = pd.DataFrame(test_files,columns=['filepath'])\n",
        "\n",
        "#converting into .csv file for future reference.\n",
        "train_files.to_csv('/content/drive/My Drive/train_file.csv')\n",
        "test_files.to_csv('/content/drive/My Drive/test_file.csv')\n"
      ],
      "metadata": {
        "id": "RYPItqCxO16d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KllpKXj_O13A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image2array(file_array):\n",
        " \"\"\"\n",
        " Reading and Converting images into numpy array by taking path of images.\n",
        " Arguments:\n",
        " file_array - (list) - list of file(path) names\n",
        " Returns:\n",
        " A numpy array of images. (np.ndarray)\n",
        " \"\"\"\n",
        " image_array = []\n",
        " for path in tqdm(file_array):\n",
        " img = cv2.imread('/content/dataset/'+path)\n",
        " img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        " img = cv2.resize(img, (224,224))\n",
        " image_array.append(np.array(img))\n",
        " image_array = np.array(image_array)\n",
        " image_array = image_array.reshape(image_array.shape[0], 224, 224, 3)\n",
        " image_array = image_array.astype('float32')\n",
        " image_array /= 255\n",
        " return np.array(image_array)\n",
        "\n",
        "train_data = image2array(train_files)\n",
        "print(\"Length of training dataset:\",train_data.shape)\n",
        "test_data = image2array(test_files)\n",
        "print(\"Length of test dataset:\",test_data.shape)"
      ],
      "metadata": {
        "id": "bO4ckUarO10O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u56Wpg5MO1xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_decoder_model():\n",
        "\n",
        "  \"\"\"\n",
        "  Used to build Convolutional Autoencoder model architecture to get compressed image data which is easier to process.\n",
        "  Returns:\n",
        "  Auto encoder model\n",
        "  \"\"\"\n",
        "  #Encoder\n",
        "  model = Sequential(name='Convolutional_AutoEncoder_Model')\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(224, 224, 3),padding='same', name='Encoding_Conv2D_1'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_1'))\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3),strides=1,kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu',padding='same', name='Encoding_Conv2D_2'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_2'))\n",
        "  model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_3'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_3'))\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_4'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=2,padding='valid', name='Encoding_MaxPooling2D_4'))\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='Encoding_Conv2D_5'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "  #Decoder\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu', padding='same', name='Decoding_Conv2D_1'))\n",
        "  model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_1'))\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same', name='Decoding_Conv2D_2'))\n",
        "  model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_2'))\n",
        "  model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same',name='Decoding_Conv2D_3'))\n",
        "  model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_3'))\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_4'))\n",
        "  model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_4'))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_5'))\n",
        "  model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_5'))\n",
        "  model.add(Conv2D(3, kernel_size=(3, 3), padding='same',activation='sigmoid',name='Decoding_Output'))\n",
        "  return model\n",
        "\n",
        "model = encoder_decoder_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5I5kjiyEO1vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wVA1VYVrO1pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "model = encoder_decoder_model()\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=6,min_delta=0.0001)\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/encoder_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "model.fit(train_data, train_data, epochs=35, batch_size=32,validation_data=(test_data,test_data),callbacks=[early_stopping,checkpoint])"
      ],
      "metadata": {
        "id": "5p1jl_irPzqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YQ16mQMPznP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(model, data, layer = 14):\n",
        "\n",
        "    \"\"\"\n",
        "    Creating a function to run the initial layers of the encoder model. (to get feature extraction from any layer of the model)\n",
        "    Arguments:\n",
        "    model - (Auto encoder model) - Trained model\n",
        "    data - (np.ndarray) - list of images to get feature extraction from trained model\n",
        "    layer - (int) - from which layer to take the features(by default = 4)\n",
        "    Returns:\n",
        "    pooled_array - (np.ndarray) - array of extracted features of given images\n",
        "    \"\"\"\n",
        "\n",
        "    encoded = K.function([model.layers[0].input],[model.layers[layer].output])\n",
        "    encoded_array = encoded([data])[0]\n",
        "    pooled_array = encoded_array.max(axis=-1)\n",
        "    return encoded_array\n",
        "\n",
        "encoded = feature_extraction(model,train_data[:10],9)"
      ],
      "metadata": {
        "id": "Mdqqds_hPzkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81qimpfmPzhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dimensionality reduction for visualization\n",
        "transform = TSNE\n",
        "trans = transform(n_components=2)\n",
        "values = trans.fit_transform(X_encoded_reshape)\n",
        "\n",
        "K = [4,5,6,7] #hyper parameter tuning\n",
        "for k in K:\n",
        "    print(\"if Number of clusters: \"+str(k))\n",
        "    #clustering the data\n",
        "    kmeans = KMeans(n_clusters = k, random_state=0).fit(X_encoded_reshape)\n",
        "    labels=kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,1,1)\n",
        "    plt.scatter(values[:,0], values[:,1], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1], c=None, s=50)\n",
        "    plt.show()\n",
        "    for row in range(k):\n",
        "        iter=0\n",
        "        plt.figure(figsize=(13,3))\n",
        "        for i,iterator in enumerate(labels):\n",
        "            if iterator == row:\n",
        "                img = cv2.imread(\"/content/dataset/\"+lisp[i])\n",
        "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "                plot_(img,\"\",\"\",1,6,iter+1,\"cluster=\"+str(row),\"\",\"\",\"\",True)\n",
        "                iter+=1\n",
        "            if iter>=5: break\n",
        "        plt.show()\n",
        "    print()"
      ],
      "metadata": {
        "id": "Q7brlanvO1eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIj5pAf0RYOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=9,algorithm='ball_tree',n_jobs=-1)\n",
        "knn.fit(np.array(data),np.array(labels))"
      ],
      "metadata": {
        "id": "k6CeFAL_RYK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOSXrCX2RYH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictions(label,N=8,isurl=False):\n",
        "\n",
        "    \"\"\"\n",
        "    Making predictions for the query images and returns N similar images from the dataset.\n",
        "    We can either pass filename or the url for the image.\n",
        "    Arguments:\n",
        "    label - (string) - file name of the query image.\n",
        "    N - (int) - Number of images to be returned\n",
        "    isurl - (string) - if query image is from google is set to True else False(By default = False)\n",
        "    \"\"\"\n",
        "\n",
        "    if isurl:\n",
        "        img = io.imread(label)\n",
        "        img = cv2.resize(img,(224,224))\n",
        "    else:\n",
        "        img_path = '/content/dataset/'+label\n",
        "        img = image.load_img(img_path, target_size=(224,224))\n",
        "    img_data = image.img_to_array(img)\n",
        "    img_data = np.expand_dims(img_data,axis=0)\n",
        "    img_data = preprocess_input(img_data)\n",
        "    feature = model.predict(img_data)\n",
        "    feature = np.array(feature).flatten().reshape(1,-1)\n",
        "    res = knn.kneighbors(feature.reshape(1,-1),return_distance=True,n_neighbors=N)\n",
        "    results_(img,list(res[1][0])[1:])"
      ],
      "metadata": {
        "id": "MDdlDriORYEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-CJGEN5RYB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6WepKNI2RX_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QWmOshFRX8f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}