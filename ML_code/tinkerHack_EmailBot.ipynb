{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NxzlixN2lvqr",
        "outputId": "5ff1f8c8-5c14-43ca-a41f-0d09b9c63adc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-70572e1d8f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test00.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                  \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s,%s\\n\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_msg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# with open('my_file.csv', 'w', newline='') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not enough arguments for format string"
          ]
        }
      ],
      "source": [
        "\n",
        "import imaplib\n",
        "import email\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import csv\n",
        "\n",
        "with open(\"credentials.yml\") as f:\n",
        "    content = f.read()\n",
        "df = pd.DataFrame(columns = ['date', 'Subject', 'From', 'to'])\n",
        "my_credentials = yaml.load(content, Loader=yaml.FullLoader)\n",
        "user, password = my_credentials[\"user\"], my_credentials[\"password\"]\n",
        "imap_url = 'imap.gmail.com'\n",
        "my_mail = imaplib.IMAP4_SSL(imap_url)\n",
        "my_mail.login(user, password)\n",
        "my_mail.select('Inbox')\n",
        "key = 'FROM'\n",
        "value = 'lachusn212@gmail.com'\n",
        "_, data = my_mail.search(None, key, value)\n",
        "\n",
        "mail_id_list = data[0].split()\n",
        "\n",
        "msgs = []\n",
        "for num in mail_id_list:\n",
        "    typ, data = my_mail.fetch(num, '(RFC822)')\n",
        "    msgs.append(data)\n",
        "\n",
        "for msg in msgs[::-1]:\n",
        "    for response_part in msg:\n",
        "        if type(response_part) is tuple:\n",
        "            my_msg=email.message_from_bytes((response_part[1]))\n",
        "            # print(\"date:\",my_msg['date'])\n",
        "            # print (\"subj:\", my_msg['subject'])\n",
        "            # print (\"from:\", my_msg['from'])\n",
        "            keys = ['date', 'Subject', 'From', 'to']\n",
        "\n",
        "            # dict2 = {x:my_msg[x] for x in keys}\n",
        "            with open('test00.csv', 'w') as f:\n",
        "               for key in my_msg.keys():\n",
        "                 f.write(\"%s,%s\\n\"%(key),(my_msg[key]))\n",
        "\n",
        "            # with open('my_file.csv', 'w', newline='') as f:\n",
        "            #   writer = csv.DictWriter(f, fieldnames=my_msg.keys())\n",
        "\n",
        "            #   # Write the header defined in the fieldnames argument\n",
        "            #   writer.writeheader()\n",
        "\n",
        "            #   # Write one or more rows\n",
        "            #   writer.writerow(my_msg)\n",
        "\n",
        "            # new = pd.DataFrame.from_dict(my_msg)\n",
        "\n",
        "            # print(new)\n",
        "\n",
        "            # import pandas as pd\n",
        "            # df = pd.DataFrame.from_dict([keys])\n",
        "            # df.to_csv('my_file.csv', index=False, header=True)\n",
        "            # print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Define the dictionary\n",
        "data = {'A':'X1', 'B':'X2', 'C':'X3'}\n",
        "\n",
        "# Open the file in writing mode\n",
        "with open('my_file11.csv', 'w', newline='') as f:\n",
        "\n",
        "    # Create the writer with the dictionary keys as headers\n",
        "    writer = csv.DictWriter(f, fieldnames=data.keys())\n",
        "\n",
        "    # Write the header defined in the fieldnames argument\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write one or more rows\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "OalbSJTytMyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyXXpxrbtMmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NldtrEBwtMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEwSWHzctMgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"test.csv\",delimiter=\",\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Eku7cDCppv8l",
        "outputId": "b25a8fe0-0031-479e-9b47-f85dcafcf098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2c83e66501c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 67, saw 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing the module\n",
        "import pandas as pd\n",
        "\n",
        "# creating the DataFrame\n",
        "marks_data = pd.DataFrame({'ID': {0: 23, 1: 43, 2: 12,\n",
        "                                 3: 13, 4: 67, 5: 89,\n",
        "                                 6: 90, 7: 56, 8: 34},\n",
        "                          'Name': {0: 'Ram', 1: 'Deep',\n",
        "                                   2: 'Yash', 3: 'Aman',\n",
        "                                   4: 'Arjun', 5: 'Aditya',\n",
        "                                   6: 'Divya', 7: 'Chalsea',\n",
        "                                   8: 'Akash' },\n",
        "                          'Marks': {0: 89, 1: 97, 2: 45, 3: 78,\n",
        "                                    4: 56, 5: 76, 6: 100, 7: 87,\n",
        "                                    8: 81},\n",
        "                          'Grade': {0: 'B', 1: 'A', 2: 'F', 3: 'C',\n",
        "                                    4: 'E', 5: 'C', 6: 'A', 7: 'B',\n",
        "                                    8: 'B'}})\n",
        "\n",
        "# determining the name of the file\n",
        "file_name = 'tinkerhack.xlsx'\n",
        "\n",
        "# saving the excel\n",
        "marks_data.to_excel(file_name)\n",
        "print('DataFrame is written to Excel File successfully.')"
      ],
      "metadata": {
        "id": "1mBZwiDvlzMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Importing libraries\n",
        "import imaplib\n",
        "import email\n",
        "\n",
        "import yaml  #To load saved login credentials from a yaml file\n",
        "\n",
        "with open(\"credentials.yml\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "# from credentials.yml import user name and password\n",
        "my_credentials = yaml.load(content, Loader=yaml.FullLoader)\n",
        "\n",
        "#Load the user name and passwd from yaml file\n",
        "user, password = my_credentials[\"user\"], my_credentials[\"password\"]\n",
        "imap_url = 'imap.gmail.com'\n",
        "my_mail = imaplib.IMAP4_SSL(imap_url)\n",
        "\n",
        "# Log in using your credentials\n",
        "my_mail.login(user, password)\n",
        "\n",
        "# Select the Inbox to fetch messages\n",
        "my_mail.select('Inbox')\n",
        "\n",
        "#Define Key and Value for email search\n",
        "\n",
        "key = 'FROM'\n",
        "value = 'lachusn212@gmail.com'\n",
        "_, data = my_mail.search(None, key, value)  #Search for emails with specific key and value\n",
        "\n",
        "mail_id_list = data[0].split()  #IDs of all emails that we want to fetch\n",
        "\n",
        "msgs = [] # empty list to capture all messages\n",
        "#Iterate through messages and extract data into the msgs list\n",
        "for num in mail_id_list:\n",
        "    typ, data = my_mail.fetch(num, '(RFC822)') #RFC822 returns whole message (BODY fetches just body)\n",
        "    msgs.append(data)\n",
        "\n",
        "#Now we have all messages, but with a lot of details\n",
        "#Let us extract the right text and print on the screen\n",
        "\n",
        "\n",
        "# NOTE that a Message object consists of headers and payloads.\n",
        "\n",
        "for msg in msgs[::-1]:\n",
        "    for response_part in msg:\n",
        "        if type(response_part) is tuple:\n",
        "            my_msg=email.message_from_bytes((response_part[1]))\n",
        "            import pandas as pd\n",
        "            df = pd.DataFrame([my_msg])\n",
        "            # print(\"_________________________________________\")\n",
        "            # print(\"date:\",my_msg['date'])\n",
        "            # print (\"subj:\", my_msg['subject'])\n",
        "            # print (\"from:\", my_msg['from'])\n",
        "            # print (\"body:\")\n",
        "            # for part in my_msg.walk():\n",
        "            #     print(part.get_content_type())\n",
        "            #     if part.get_content_type() == 'text/plain':\n",
        "            #        print (\"Content \",part.get_payload())\n",
        "            print(df)\n",
        "!python3 \"/content/Text_Sum.py\"\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OK_Vbl-slzDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d01b59-1e04-4509-a4fe-843458bfece4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0         1           2         3                      4   \\\n",
            "0  Delivered-To  Received  X-Received  ARC-Seal  ARC-Message-Signature   \n",
            "\n",
            "                           5            6         7             8   \\\n",
            "0  ARC-Authentication-Results  Return-Path  Received  Received-SPF   \n",
            "\n",
            "                       9   ...          15        16                    17  \\\n",
            "0  Authentication-Results  ...  X-Received  Reply-To  X-No-Auto-Attachment   \n",
            "\n",
            "           18          19    20       21    22  23            24  \n",
            "0  References  Message-ID  Date  Subject  From  To  Content-Type  \n",
            "\n",
            "[1 rows x 25 columns]\n",
            "python3: can't open file '/content/Text_Sum.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzQjvY4lj_z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Importing libraries\n",
        "import imaplib\n",
        "import email\n",
        "\n",
        "import yaml  #To load saved login credentials from a yaml file\n",
        "import csv\n",
        "\n",
        "with open(\"/content/credentials.yml\") as f:\n",
        "    content = f.read()\n",
        "\n",
        "# from credentials.yml import user name and password\n",
        "my_credentials = yaml.load(content, Loader=yaml.FullLoader)\n",
        "\n",
        "#Load the user name and passwd from yaml file\n",
        "user, password = my_credentials[\"user\"], my_credentials[\"password\"]\n",
        "imap_url = 'imap.gmail.com'\n",
        "my_mail = imaplib.IMAP4_SSL(imap_url)\n",
        "\n",
        "# Log in using your credentials\n",
        "my_mail.login(user, password)\n",
        "\n",
        "# Select the Inbox to fetch messages\n",
        "my_mail.select('Inbox')\n",
        "\n",
        "#Define Key and Value for email search\n",
        "\n",
        "key = 'FROM'\n",
        "value = 'malu22leena@gmail.com'\n",
        "_, data = my_mail.search(None, key, value)  #Search for emails with specific key and value\n",
        "\n",
        "mail_id_list = data[0].split()  #IDs of all emails that we want to fetch\n",
        "\n",
        "msgs = [] # empty list to capture all messages\n",
        "#Iterate through messages and extract data into the msgs list\n",
        "for num in mail_id_list:\n",
        "    typ, data = my_mail.fetch(num, '(RFC822)') #RFC822 returns whole message (BODY fetches just body)\n",
        "    msgs.append(data)\n",
        "\n",
        "#Now we have all messages, but with a lot of details\n",
        "#Let us extract the right text and print on the screen\n",
        "\n",
        "\n",
        "# NOTE that a Message object consists of headers and payloads.\n",
        "k = [['Date', 'Subject','From','Content']]\n",
        "l = []\n",
        "for msg in msgs[::-1]:\n",
        "    for response_part in msg:\n",
        "        if type(response_part) is tuple:\n",
        "            l= []\n",
        "            my_msg=email.message_from_bytes((response_part[1]))\n",
        "            #print(my_msg.keys())\n",
        "            import pandas as pd\n",
        "            df = pd.DataFrame([my_msg])\n",
        "            df.to_csv(\"newFile.csv\")\n",
        "            l.append(my_msg['date'])\n",
        "            l.append(my_msg['subject'])\n",
        "            l.append(my_msg['from'])\n",
        "            for part in my_msg.walk():\n",
        "                if part.get_content_type() == 'text/plain':\n",
        "                   l.append(part.get_payload())\n",
        "            k.append(l)\n",
        "            # my_msg=email.message_from_bytes((response_part[1]))\n",
        "            # print(\"_________________________________________\")\n",
        "            # print(\"date:\",my_msg['date'])\n",
        "            # print (\"subj:\", my_msg['subject'])\n",
        "            # print (\"from:\", my_msg['from'])\n",
        "            # print (\"body:\")\n",
        "            # for part in my_msg.walk():\n",
        "            #     print(part.get_content_type())\n",
        "            #     if part.get_content_type() == 'text/plain':\n",
        "            #        print (\"Content \",part.get_payload())\n",
        "# !python3 \"/content/Text_Sum.py\"\n",
        "print(k)\n",
        "with open(\"NameOfFile.csv\",  \"w\") as csvfile:\n",
        "    write = csv.writer(csvfile)\n",
        "\n",
        "    # for x in k:\n",
        "    #     write.writerow(map(lambda x: [x], k))\n",
        "    write.writerows(k)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fhDpKIhj_w7",
        "outputId": "db9738bf-157d-4c42-9e91-c3490fe26eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Date', 'Subject', 'From', 'Content'], ['Sat, 17 Dec 2022 12:40:57 +0530', 'Extension', 'AARSHA LEENA <malu22leena@gmail.com>', 'https://chrome.google.com/webstore/detail/gmass-powerful-mail-merge/ehomdgjhgmbidokdgicgmdiedadncbgf\\r\\n'], ['Mon, 12 Dec 2022 19:36:59 +0530', 'e sample Python code for creating a chatbot that reads email and\\r\\n summarizes an upcoming schedule', 'AARSHA LEENA <malu22leena@gmail.com>', '# Import necessary libraries\\r\\nimport gmail_api\\r\\nimport pandas as pd\\r\\nimport nltk\\r\\n\\r\\n# Use the Gmail API to connect to the user\\'s email account\\r\\n# and retrieve their emails\\r\\ngmail = gmail_api.connect(user_id, access_token)\\r\\nemails = gmail.get_emails()\\r\\n\\r\\n# Use NLTK to parse the emails and extract relevant information\\r\\n# about the user\\'s upcoming schedule\\r\\nschedule_info = []\\r\\nfor email in emails:\\r\\n  body = email[\\'body\\']\\r\\n  dates = nltk.extract_dates(body)\\r\\n  events = nltk.extract_events(body)\\r\\n  for date, event in zip(dates, events):\\r\\n    schedule_info.append({\\r\\n      \\'date\\': date,\\r\\n      \\'event\\': event\\r\\n    })\\r\\n\\r\\n# Use Pandas to organize the extracted information\\r\\nschedule_df = pd.DataFrame(schedule_info)\\r\\n\\r\\n# Generate a summary of the user\\'s upcoming schedule\\r\\nsummary = \"\"\\r\\nfor index, row in schedule_df.iterrows():\\r\\n  summary += f\"On {row[\\'date\\']}, you have {row[\\'event\\']}\\\\n\"\\r\\n\\r\\n# Print the summary to the console\\r\\nprint(summary)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n#This code uses the Gmail API to connect to the user\\'s email account and\\r\\nretrieve their emails. It then uses NLTK to parse the emails and extract\\r\\nrelevant information about the user\\'s upcoming schedule, such as the dates\\r\\nand events. Finally, it uses Pandas to organize the extracted information\\r\\nand generates a summary of the user\\'s upcoming schedule. The summary is\\r\\nthen printed to the console.\\r\\n\\r\\nNote: This code is for demonstration purposes only and may not work out of\\r\\nthe box. It is intended to provide a high-level overview of the process for\\r\\ncreating a chatbot that reads email and summarizes an upcoming schedule\\r\\nusing Python.\\r\\n'], ['Sat, 10 Dec 2022 13:42:51 +0530', 'Fwd: [Tink-Her-Hack] Venue details and event guidelines', 'AARSHA LEENA <malu22leena@gmail.com>', \"---------- Forwarded message ---------\\r\\nFrom: Tinkerhub WIT <tinkerhubwit@gmail.com>\\r\\nDate: Sat, 10 Dec, 2022, 13:24\\r\\nSubject: [Tink-Her-Hack] Venue details and event guidelines\\r\\nTo:\\r\\n\\r\\n\\r\\nHey Good Afternoon=E2=9C=A8,\\r\\n\\r\\nGreetings from TinkerHub WIT =F0=9F=8E=89.\\r\\n\\r\\nYour initiative towards participating in Tink-Her-Hack is worth\\r\\nappreciating. This mail is to let you know about the venue details.\\r\\n\\r\\nRegion : Kochi\\r\\n\\r\\nVenue : Toc H Institute of Science and Technology\\r\\n\\r\\nLocation details : https://goo.gl/maps/ZqzhBzWDcK1Bs6x2A\\r\\n\\r\\nDate & Time : 9:00am 17 December 2022 - 4:00PM 18 December 2022.\\r\\n\\r\\nGuidelines on how to reach the location :\\r\\n\\r\\nMinor railway station: (MNTT)MULANTURUTTI\\r\\n\\r\\nMajor railway station: (ERS)ERNAKULAM JN\\r\\n\\r\\nTransport from station to venue:\\r\\n\\r\\n- Auto rickshaws available at all times\\r\\n\\r\\n- Buses available from ERS Ernakulam JN\\r\\n\\r\\nHere are some basic guidelines that you need to follow :\\r\\n\\r\\n\\r\\n   -\\r\\n\\r\\n   All the team members should report to the venue by 9:00am on 17 December=\\r\\n.\\r\\n   -\\r\\n\\r\\n   It's an overnight hackathon, so after entering the campus you aren't\\r\\n   allowed to go out until 4pm, 18th December.\\r\\n   -\\r\\n\\r\\n   Your stay, food, refreshments from 17th December 9am to 18th December\\r\\n   4pm will be provided by us.\\r\\n   -\\r\\n\\r\\n   Please fill this form <https://forms.gle/bHUZd1iFxTGtZryJA> (fill this\\r\\n   form by tomorrow 4:00pm) to let us know your food preferences of all you=\\r\\nr\\r\\n   team members.\\r\\n   -\\r\\n\\r\\n   We cannot afford to stay for extra days for any team.\\r\\n   -\\r\\n\\r\\n   Arriving late without informing us will be considered as disqualified\\r\\n   and no extra time will be allotted for that team.\\r\\n   -\\r\\n\\r\\n   We cannot provide any extra stay for anyone apart from the registered\\r\\n   team members\\r\\n   -\\r\\n\\r\\n   Please make sure that you carry your personal belongings that are\\r\\n   necessary for these 2 days like medicines, basic clothes, sweaters, etc.\\r\\n   -\\r\\n\\r\\n   Please book your tickets in advance to avoid last minute rush.\\r\\n\\r\\n\\r\\nPlease call  Nyasa : +91 97467 17708 in case you face any challenges to\\r\\nreach the venue\\r\\n\\r\\nYou can reach out tinkerhubwit@gmail.com or Meenu : 9633164358 and Devika :\\r\\n6235365959 for any event related queries.\\r\\n\\r\\nExcited to see you all there =F0=9F=98=80\\r\\n\\r\\nRegards,\\r\\n\\r\\nTinkerHub WIT\\r\\n\"], ['Sun, 28 Aug 2022 18:57:14 +0530', 'Fwd: Links for KDISC project', 'AARSHA LEENA <malu22leena@gmail.com>', '---------- Forwarded message ---------\\r\\nFrom: AARSHA LEENA <malu22leena@gmail.com>\\r\\nDate: Thu, Jun 30, 2022, 8:40 PM\\r\\nSubject: Fwd: Links for KDISC project\\r\\nTo: <ashnaregi007@gmail.com>\\r\\n\\r\\n\\r\\n\\r\\n---------- Forwarded message ---------\\r\\nFrom: Dr P Suresh <psuresh@mgits.ac.in>\\r\\nDate: Thu, Jun 30, 2022, 4:51 PM\\r\\nSubject: Links for KDISC project\\r\\nTo: <malu22leena@gmail.com>\\r\\n\\r\\n\\r\\n1)\\r\\nhttps://www.thehansindia.com/news/cities/hyderabad/hyderabadcrowdfunding-brings-ray-of-hope-to-struggling-handloom-artisans-650515\\r\\n\\r\\n2)https://www.blagungan.se/en/interior/willow-tree-statues/\\r\\n\\r\\n3) https://www.willowtree.com/simple-joys/\\r\\n\\r\\n4)\\r\\nhttps://www.exoticindiaart.com/?gclid=CjwKCAjwk_WVBhBZEiwAUHQCmQwbtgzJhWfV_70PTJSsVpGJ1pBTbzXg-Kyzs08UR0UHYbla-BfYoxoCylUQAvD_BwE\\r\\n\\r\\nRegards,\\r\\n\\r\\nSuresh\\r\\n']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from email.utils import parsedate_tz\n",
        "print(parsedate_tz('Fri, 15 May 2009 17:58:28 +0700'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDJ47vyqj_t1",
        "outputId": "4a86ed53-be2e-4f8d-bc9c-65929291cf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2009, 5, 15, 17, 58, 28, 0, 1, -1, 25200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joHx1ds6j_q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyaLttblj_oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOVNyH8Yj_lc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}